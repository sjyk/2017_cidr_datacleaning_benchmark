\section{Related Work}
There have also been a number of different proposals for both quantitative and qualitative data quality metrics~\cite{DBLP:journals/cacm/PipinoLW02, DBLP:journals/jdiq/CheahP15, DBLP:journals/jdiq/EvenS09,DBLP:journals/jdiq/SessionsV09, DBLP:journals/tkde/FanGLX11,DBLP:journals/sigmetrics/KeetonMW09}.
Most of the techniques rely on assessing the number of violated constraints or tests designed by the user, or qualitatively measure the number of erroneous decisions made by programs using the data.
In terms of probabilistic techniques, Sessions et al.~\cite{DBLP:journals/jdiq/SessionsV09} learn a Bayesian Network model to represent the data and measured how well the model fits the data.


Mention the data generator work  for synthesizing datasets with certain properites.   Also the subspace clustering benchmarks, maybe graph generators as well.

https://sourceforge.net/projects/febrl

Backtesting and other robustness work.

Open AI Bench, UCI datastore.


